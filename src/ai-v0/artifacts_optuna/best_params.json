{
  "n_layers": 2,
  "n_units_l0": 32,
  "n_units_l1": 37,
  "alpha": 0.0007526093064331545,
  "learning_rate_init": 0.0001094286754524124,
  "batch_size": 64,
  "activation": "tanh"
}